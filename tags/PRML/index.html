<!DOCTYPE html>
<html class="has-navbar-fixed-top">
<head><meta name="generator" content="Hexo 3.8.0">
    <meta charset="utf-8">
<title>Tag: PRML - Wiljohn&#39;s Blog</title>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.css">






    <meta property="og:type" content="website">
<meta property="og:title" content="Wiljohn&#39;s Blog">
<meta property="og:url" content="http://wiljohn.top/tags/PRML/index.html">
<meta property="og:site_name" content="Wiljohn&#39;s Blog">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Wiljohn&#39;s Blog">





<link rel="icon" href="/favicon.png">


<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Ovo|Source+Code+Pro">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/bulma/0.6.2/css/bulma.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/css/justifiedGallery.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css">

<link rel="stylesheet" href="/css/style.css">

<script defer src="//use.fontawesome.com/releases/v5.0.8/js/all.js"></script>


    
    

    
    
    
    
    


</head>
<body>
    
<nav class="navbar is-transparent is-fixed-top navbar-main" role="navigation" aria-label="main navigation">
    <div class="container">
        <div class="navbar-brand">
            <a class="navbar-item navbar-logo" href="/">
                
                <img src="/images/logo.png" alt="" height="28">
                
            </a>
            <div class="navbar-burger">
                <span></span>
                <span></span>
                <span></span>
            </div>
        </div>
        
        <div class="navbar-menu navbar-start">
            
            <a class="navbar-item " href="/archives">Archives</a>
            
            <a class="navbar-item " href="/tags">Tags</a>
            
        </div>
        
        <div class="navbar-menu navbar-end">
            
            <a class="navbar-item search" title="Search" href="javascript:;">
                <i class="fas fa-search"></i>
            </a>
            
            
            
            <a class="navbar-item" title="GitHub" href="https://github.com/wiljohnhong">
                
                <i class="fab-github"></i>
                
            </a>
               
            
        </div>
    </div>
</nav>

    <section class="section section-heading">
    <div class="container">
        <div class="content">
            <h5>#PRML</h5>
        </div>
    </div>
</section>
<section class="section">
    <div class="container">
    
        <article class="article content gallery" itemscope="" itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2019/03/23/PRML3-3/" itemprop="url">(PRML Notes) 3.3 Bayesian Linear Regression</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            <time datetime="2019-03-23T10:54:04.000Z" itemprop="datePublished">Mar 23 2019</time>
        </span>
        
        
        <span class="column is-narrow">
            
            
            10 minutes read (About 1494 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <blockquote>
<p>A series of notes taken from <em>Pattern Recognition and Machine Learning</em>.</p>
</blockquote>
<p>This section turns to a <em>Bayesian view</em> of linear regression, which avoids the over-fitting problem of MLE and also leads to automatic methods of determining the model complexity using a single training data set alone.</p>
        <p class="article-more-link">
            <a href="/2019/03/23/PRML3-3/#more">Read More</a>
        </p>
    
    </div>
    
    
</article>




    
        <article class="article content gallery" itemscope="" itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2019/03/23/PRML3-2/" itemprop="url">(PRML Notes) 3.2 The Bias-Variance Decomposition</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            <time datetime="2019-03-23T07:25:04.000Z" itemprop="datePublished">Mar 23 2019</time>
        </span>
        
        
        <span class="column is-narrow">
            
            
            8 minutes read (About 1195 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <blockquote>
<p>A series of notes taken from <em>Pattern Recognition and Machine Learning</em>.</p>
</blockquote>
<p>In the last section we remain a question about how to determine the regularization parameter <span class="math inline">\(\lambda\)</span>, so that the model can be applied better to new data set. Seeking solution that minimizes both <span class="math inline">\(\mathbf{w}\)</span> and <span class="math inline">\(\lambda\)</span> is not right approach since this leads to unregularized solution <span class="math inline">\(\lambda=0\)</span>.</p>
<p>This section focuses on the <em>frequentist view</em> of the model complexity issue, known as <strong>bias-variance trade-off</strong>.</p>
        <p class="article-more-link">
            <a href="/2019/03/23/PRML3-2/#more">Read More</a>
        </p>
    
    </div>
    
    
</article>




    
        <article class="article content gallery" itemscope="" itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2019/03/22/PRML3-1/" itemprop="url">(PRML Notes) 3.1 Linear Basis Function Models</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            <time datetime="2019-03-22T06:30:04.000Z" itemprop="datePublished">Mar 22 2019</time>
        </span>
        
        
        <span class="column is-narrow">
            
            
            13 minutes read (About 1947 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <blockquote>
<p>A series of notes taken from <em>Pattern Recognition and Machine Learning</em>.</p>
</blockquote>
<p>A simplest regression model for <span class="math inline">\(D\)</span>-dimensional input variable <span class="math inline">\(\mathbf{x}=\left(x_{1}, \dots, x_{D}\right)^{\mathrm{T}}\)</span> is <span class="math display">\[
y(\mathbf{x}, \mathbf{w})=w_{0}+w_{1} x_{1}+\ldots+w_{D} x_{D}
\]</span> The key property of this model is that it is a linear function of parameters <span class="math inline">\(w_{0}, \dots, w_{D}\)</span>. This model can be extended to linear combination of fixed nonlinear functions of <span class="math inline">\(\mathbf{x}\)</span> <span class="math display">\[
y(\mathbf{x}, \mathbf{w})=w_{0}+\sum_{j=1}^{M-1} w_{j} \phi_{j}(\mathbf{x})
\]</span></p>
        <p class="article-more-link">
            <a href="/2019/03/22/PRML3-1/#more">Read More</a>
        </p>
    
    </div>
    
    
</article>




    
        <article class="article content gallery" itemscope="" itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2019/03/17/PRML2-5/" itemprop="url">(PRML Notes) 2.5 Nonparametric Methods</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            <time datetime="2019-03-17T06:02:04.000Z" itemprop="datePublished">Mar 17 2019</time>
        </span>
        
        
        <span class="column is-narrow">
            
            
            9 minutes read (About 1286 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <blockquote>
<p>A series of notes taken from <em>Pattern Recognition and Machine Learning</em>.</p>
</blockquote>
<p>Limitation of previous parametric approach to density modeling is that the chosen density might be a poor model of the distribution that generates data. This section will focus mainly on simple frequentist nonparametric methods.</p>
<h2 id="histogram-methods">Histogram Methods</h2>
<p>Standard histogram methods simply partition <span class="math inline">\(x\)</span> into distinct bins of width <span class="math inline">\(\Delta_i\)</span>, and count the number of <span class="math inline">\(n_i\)</span> of observations of <span class="math inline">\(x\)</span> falling in bin <span class="math inline">\(i\)</span>. Then the probability density in each bin is given by</p>
        <p class="article-more-link">
            <a href="/2019/03/17/PRML2-5/#more">Read More</a>
        </p>
    
    </div>
    
    
</article>




    
        <article class="article content gallery" itemscope="" itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2019/03/16/PRML2-4/" itemprop="url">(PRML Notes) 2.4 The Exponential Family</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            <time datetime="2019-03-16T06:26:04.000Z" itemprop="datePublished">Mar 16 2019</time>
        </span>
        
        
        <span class="column is-narrow">
            
            
            12 minutes read (About 1760 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <blockquote>
<p>A series of notes taken from <em>Pattern Recognition and Machine Learning</em>.</p>
</blockquote>
<p>The exponential family is defined by <span class="math display">\[
p(\mathbf{x} | \boldsymbol{\eta})=h(\mathbf{x}) g(\boldsymbol{\eta}) \exp \left\{\boldsymbol{\eta}^{\mathrm{T}} \mathbf{u}(\mathbf{x})\right\}
\]</span> here <span class="math inline">\(\boldsymbol{\eta}\)</span> is called the <strong>natural parameters</strong> of the distribution, <span class="math inline">\(g(\boldsymbol{\eta})\)</span> ensures the normalization. Now we will see that all the distributions we have seen so far are actually members in this family.</p>
        <p class="article-more-link">
            <a href="/2019/03/16/PRML2-4/#more">Read More</a>
        </p>
    
    </div>
    
    
</article>




    
        <article class="article content gallery" itemscope="" itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2019/03/15/PRML2-3-7~9/" itemprop="url">(PRML Notes) 2.3.7-9 Miscellaneous of Gaussian</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            <time datetime="2019-03-15T08:42:04.000Z" itemprop="datePublished">Mar 15 2019</time>
        </span>
        
        
        <span class="column is-narrow">
            
            
            11 minutes read (About 1720 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <blockquote>
<p>A series of notes taken from <em>Pattern Recognition and Machine Learning</em>.</p>
</blockquote>
<h2 id="students-t-distribution">Student's t-distribution</h2>
<p>Recall that for a univariate Gaussian <span class="math inline">\(\mathcal{N}(x|\mu,\tau^{-1})\)</span>, its conjugate prior when <span class="math inline">\(\mu\)</span> is known and <span class="math inline">\(\tau^{-1}\)</span> is unknown is a Gamma distribution <span class="math inline">\(\mathrm{Gam}(\tau|a,b)\)</span>. <strong>Student's t-distribution</strong> is the result where we integrate out the precision of the posterior</p>
        <p class="article-more-link">
            <a href="/2019/03/15/PRML2-3-7~9/#more">Read More</a>
        </p>
    
    </div>
    
    
</article>




    
        <article class="article content gallery" itemscope="" itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2019/03/02/PRML2-3-6/" itemprop="url">(PRML Notes) 2.3.6 Bayesian Inference for Gaussian</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            <time datetime="2019-03-02T08:07:04.000Z" itemprop="datePublished">Mar 2 2019</time>
        </span>
        
        
        <span class="column is-narrow">
            
            
            10 minutes read (About 1453 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <blockquote>
<p>A series of notes taken from <em>Pattern Recognition and Machine Learning</em>.</p>
</blockquote>
<p>Now for univariate Gaussian, we use <span class="math inline">\(\mathtt{x} = \{x_1,...,x_N\}​\)</span> to denote the <span class="math inline">\(N​\)</span> observations, and <span class="math inline">\(\mathbf{X}=\{\mathbf{x}_1,...,\mathbf{x}_N\}​\)</span> for the multivariate Gaussian. For convenience, the likelihood functions of the observed data given mean and variance are written below <span class="math display">\[
p(\mathtt{x}|\mu,\sigma^2) = \frac{1}{(2\pi\sigma^2)^{N/2}}\exp\left\{ -\sum_{n=1}^N\frac{(x_n-\mu)^2}{2\sigma^2} \right\}
\]</span></p>
<p><span class="math display">\[
p(\mathbf{X}| \boldsymbol{\mu},\mathbf{\Sigma}) = \frac{1}{(2\pi)^{ND/2}} \frac{1}{|\mathbf{\Sigma}|^{N/2}} \exp\left\{ -\frac{1}{2} \sum_{n=1}^{N}(\mathbf{x}_n- \boldsymbol{\mu})^T\mathbf{\Sigma}^{-1}(\mathbf{x}_n- \boldsymbol{\mu}) \right\}
\]</span></p>
<p>In this section a Bayesian treatment that mainly focuses on univariate case by introducing prior will be developed.</p>
        <p class="article-more-link">
            <a href="/2019/03/02/PRML2-3-6/#more">Read More</a>
        </p>
    
    </div>
    
    
</article>




    
        <article class="article content gallery" itemscope="" itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2019/03/02/PRML2-3-4~5/" itemprop="url">(PRML Notes) 2.3.4-5 Frequentist Estimate for Gaussian</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            <time datetime="2019-03-02T06:20:04.000Z" itemprop="datePublished">Mar 2 2019</time>
        </span>
        
        
        <span class="column is-narrow">
            
            
            11 minutes read (About 1576 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <blockquote>
<p>A series of notes taken from <em>Pattern Recognition and Machine Learning</em>.</p>
</blockquote>
<h2 id="maximum-likelihood-for-gaussian">Maximum Likelihood for Gaussian</h2>
<p>Given a dataset <span class="math inline">\(\mathbf{X} = (\mathbf{x}_1,...,\mathbf{N})^T\)</span> where <span class="math inline">\(\mathbf{x_n}\)</span> are drawn independently from a multivariate Gaussian. To derive MLE, the log likelihood of the dataset is given by <span class="math display">\[
\begin{align}
\ln p(\mathbf{X}|\boldsymbol{\mu},\mathbf{\Sigma}) &amp;= \ln \prod_{n=1}^{N}\frac{1}{(2\pi)^{D/2}} \frac{1}{|\mathbf{\Sigma}|^{1/2}} \exp\left\{ -\frac{1}{2} (\mathbf{x}_n- \boldsymbol{\mu})^T\mathbf{\Sigma}^{-1}(\mathbf{x}_n- \boldsymbol{\mu}) \right\}
\\ &amp;= -\frac{ND}{2}\ln (2\pi) - \frac{N}{2}\ln|\mathbf{\Sigma}|  - \frac{1}{2}\sum_{n=1}^N (\mathbf{x}_n- \boldsymbol{\mu})^T\mathbf{\Sigma}^{-1}(\mathbf{x}_n- \boldsymbol{\mu})
\end{align}
\]</span></p>
        <p class="article-more-link">
            <a href="/2019/03/02/PRML2-3-4~5/#more">Read More</a>
        </p>
    
    </div>
    
    
</article>




    
        <article class="article content gallery" itemscope="" itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2019/03/01/PRML2-3-1~3/" itemprop="url">(PRML Notes) 2.3.1-3 Conditional and Marginal Gaussian</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            <time datetime="2019-03-01T07:29:04.000Z" itemprop="datePublished">Mar 1 2019</time>
        </span>
        
        
        <span class="column is-narrow">
            
            
            11 minutes read (About 1660 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <blockquote>
<p>A series of notes taken from <em>Pattern Recognition and Machine Learning</em>.</p>
</blockquote>
<p>If two sets of variables are jointly Gaussian, then the conditional distribution of one conditioned on the other is again Gaussian, and the marginal of either set is also Gaussian.</p>
<h2 id="conditional-gaussian">Conditional Gaussian</h2>
<p>If we partition <span class="math inline">\(\mathbf{x}\)</span> into two disjoint subsets <span class="math inline">\(\mathbf{x}_a\)</span> and <span class="math inline">\(\mathbf{x}_b\)</span>, w.l.o.g. we can take <span class="math inline">\(\mathbf{x}_a\)</span> to be the first <span class="math inline">\(M\)</span> components of <span class="math inline">\(\mathbf{x}\)</span>, then correspondingly we have <span class="math display">\[
\mathbf{x} = \left(\matrix{\mathbf{x}_a\\\mathbf{x}_b}\right) \ \ \boldsymbol{\mu} = \left(\matrix{\boldsymbol{\mu}_a\\\boldsymbol{\mu}_b}\right) \ \ \mathbf{\Sigma} = \left(\matrix{\mathbf{\Sigma}_{aa}&amp;\mathbf{\Sigma}_{ab}\\\mathbf{\Sigma}_{ba} &amp; \mathbf{\Sigma}_{bb}}\right) \ \ \mathbf{\Lambda} = \left(\matrix{\mathbf{\Lambda}_{aa}&amp;\mathbf{\Lambda}_{ab}\\\mathbf{\Lambda}_{ba} &amp; \mathbf{\Lambda}_{bb}}\right)
\]</span></p>
        <p class="article-more-link">
            <a href="/2019/03/01/PRML2-3-1~3/#more">Read More</a>
        </p>
    
    </div>
    
    
</article>




    
        <article class="article content gallery" itemscope="" itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            <a href="/2019/02/28/PRML2-3-0/" itemprop="url">(PRML Notes) 2.3.0 Gaussian Distribution</a>
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            <time datetime="2019-02-28T12:36:04.000Z" itemprop="datePublished">Feb 28 2019</time>
        </span>
        
        
        <span class="column is-narrow">
            
            
            12 minutes read (About 1813 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <blockquote>
<p>A series of notes taken from <em>Pattern Recognition and Machine Learning</em>.</p>
</blockquote>
<h2 id="introduction">Introduction</h2>
<p>In the case of single variable <span class="math inline">\(x​\)</span>, the Gaussian distribution can be written in the form <span class="math display">\[
\mathcal{N}(x|\mu,\sigma^2) = \frac{1}{\sqrt{2\pi}\sigma}\exp\left\{ -\frac{(x-\mu)^2}{2\sigma^2} \right\}
\]</span> with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. For a <span class="math inline">\(D\)</span>-dimensional vector <span class="math inline">\(\mathbf{x}\)</span>, the multivariate Gaussian distribution takes the form <span class="math display">\[
\mathcal{N}(\mathbf{x}| \boldsymbol{\mu},\mathbf{\Sigma}) = \frac{1}{(2\pi)^{D/2}} \frac{1}{|\mathbf{\Sigma}|^{1/2}} \exp\left\{ -\frac{1}{2} (\mathbf{x}- \boldsymbol{\mu})^T\mathbf{\Sigma}^{-1}(\mathbf{x}- \boldsymbol{\mu}) \right\}
\]</span></p>
        <p class="article-more-link">
            <a href="/2019/02/28/PRML2-3-0/#more">Read More</a>
        </p>
    
    </div>
    
    
</article>




    
    
        
<nav class="pagination is-centered is-rounded" role="navigation" aria-label="pagination">
    <div class="pagination-previous is-invisible is-hidden-mobile">
        <a href="/tags/PRML/page/0/">Prev</a>
    </div>
    <div class="pagination-next">
        <a href="/tags/PRML/page/2/">Next</a>
    </div>
    <ul class="pagination-list is-hidden-mobile">
        
        <li><a class="pagination-link is-current" href="/tags/PRML/">1</a></li>
        
        <li><a class="pagination-link" href="/tags/PRML/page/2/">2</a></li>
        
    </ul>
</nav>
    
    </div>
</section>
    <footer class="footer">
    <div class="container">
        <div class="columns content">
            <div class="column is-narrow has-text-centered">
                &copy; 2019 wiljohn&nbsp;
                Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> & <a href="http://github.com/ppoffice/hexo-theme-minos">Minos</a>
            </div>
            <div class="column is-hidden-mobile"></div>

            
            <div class="column is-narrow">
                <div class="columns is-mobile is-multiline is-centered">
                
                    
                <a class="column is-narrow has-text-black" title="GitHub" href="https://github.com/wiljohnhong">
                    
                    GitHub
                    
                </a>
                
                </div>
            </div>
            
            
        </div>
    </div>
</footer>
    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script>

<!-- test if the browser is outdated -->
<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.js"></script>
<script>
    $(document).ready(function () {
        // plugin function, place inside DOM ready function
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        })
    });
</script>

<script>
    window.FontAwesomeConfig = {
        searchPseudoElements: true
    }
    moment.locale("en-AU");
</script>


    
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        "HTML-CSS": {matchFontHeight: false},
        SVG: {matchFontHeight: false},
        CommonHTML: {matchFontHeight: false}
    });
</script>


    
    
<script src="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/js/lightgallery-all.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/js/jquery.justifiedGallery.min.js"></script>
<script>
    (function ($) {
        $(document).ready(function () {
            if (typeof($.fn.lightGallery) === 'function') {
                $('.article.gallery').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof($.fn.justifiedGallery) === 'function') {
                $('.justified-gallery').justifiedGallery();
            }
        });
    })(jQuery);
</script>

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
    <style>
        .hljs {
            position: relative;
        }

        .hljs .clipboard-btn {
            float: right;
            color: #9a9a9a;
            background: none;
            border: none;
        }

        .hljs > .clipboard-btn {
            display: none;
            position: absolute;
            right: 4px;
            top: 4px;
        }

        .hljs:hover > .clipboard-btn {
            display: inline;
        }

        .hljs > figcaption > .clipboard-btn {
            margin-right: 4px;
        }
    </style>
    <script>
      $(document).ready(function () {
        $('figure.hljs').each(function(i, figure) {
          var codeId = 'code-' + i;
          var code = figure.querySelector('.code');
          var copyButton = $('<button>Copy <i class="far fa-clipboard"></i></button>');
          code.id = codeId;
          copyButton.addClass('clipboard-btn');
          copyButton.attr('data-clipboard-target-id', codeId);

          var figcaption = figure.querySelector('figcaption');

          if (figcaption) {
            figcaption.append(copyButton[0]);
          } else {
            figure.prepend(copyButton[0]);
          }
        })

        var clipboard = new ClipboardJS('.clipboard-btn', {
          target: function(trigger) {
            return document.getElementById(trigger.getAttribute('data-clipboard-target-id'));
          }
        });
      })
    </script>

    


<script src="/js/script.js"></script>

    
    <div class="searchbox ins-search">
    <div class="searchbox-mask"></div>
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="Type something...">
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: 'Posts',
                PAGES: 'Pages',
                CATEGORIES: 'Categories',
                TAGS: 'Tags',
                UNTITLED: '(Untitled)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script src="/js/insight.js"></script>
    
</body>
</html>