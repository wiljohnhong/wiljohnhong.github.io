<!DOCTYPE html>
<html class="has-navbar-fixed-top">
<head><meta name="generator" content="Hexo 3.8.0">
    <meta charset="utf-8">
<title>(PRML Notes) 4.4 The Laplace Approximation - Wiljohn&#39;s Blog</title>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.css">








    <meta name="description" content="A series of notes taken from Pattern Recognition and Machine Learning.  For a Bayesian treatment of logistic regression, it is more complex than that of linear regression discuss before, since we can">
<meta name="keywords" content="PRML">
<meta property="og:type" content="article">
<meta property="og:title" content="(PRML Notes) 4.4 The Laplace Approximation">
<meta property="og:url" content="http://wiljohn.top/2019/04/14/PRML4-4/index.html">
<meta property="og:site_name" content="Wiljohn&#39;s Blog">
<meta property="og:description" content="A series of notes taken from Pattern Recognition and Machine Learning.  For a Bayesian treatment of logistic regression, it is more complex than that of linear regression discuss before, since we can">
<meta property="og:locale" content="en">
<meta property="og:image" content="http://wiljohn-blog.oss-cn-shanghai.aliyuncs.com/19-04-04/Screenshot%20from%202019-04-14%2017-45-24.png">
<meta property="og:updated_time" content="2019-04-14T12:04:25.907Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="(PRML Notes) 4.4 The Laplace Approximation">
<meta name="twitter:description" content="A series of notes taken from Pattern Recognition and Machine Learning.  For a Bayesian treatment of logistic regression, it is more complex than that of linear regression discuss before, since we can">
<meta name="twitter:image" content="http://wiljohn-blog.oss-cn-shanghai.aliyuncs.com/19-04-04/Screenshot%20from%202019-04-14%2017-45-24.png">





<link rel="icon" href="/favicon.png">


<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Ovo|Source+Code+Pro">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/bulma/0.6.2/css/bulma.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/css/justifiedGallery.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css">

<link rel="stylesheet" href="/css/style.css">

<script defer src="//use.fontawesome.com/releases/v5.0.8/js/all.js"></script>


    
    

    
    
    
    
    


</head>
<body>
    
<nav class="navbar is-transparent is-fixed-top navbar-main" role="navigation" aria-label="main navigation">
    <div class="container">
        <div class="navbar-brand">
            <a class="navbar-item navbar-logo" href="/">
                
                <img src="/images/logo.png" alt="" height="28">
                
            </a>
            <div class="navbar-burger">
                <span></span>
                <span></span>
                <span></span>
            </div>
        </div>
        
        <div class="navbar-menu navbar-start">
            
            <a class="navbar-item " href="/archives">Archives</a>
            
            <a class="navbar-item " href="/tags">Tags</a>
            
        </div>
        
        <div class="navbar-menu navbar-end">
            
            <a class="navbar-item search" title="Search" href="javascript:;">
                <i class="fas fa-search"></i>
            </a>
            
            
            
            <a class="navbar-item" title="GitHub" href="https://github.com/wiljohnhong">
                
                <i class="fab-github"></i>
                
            </a>
               
            
        </div>
    </div>
</nav>

    <section class="section">
    <div class="container">
    <article class="article content gallery" itemscope="" itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            (PRML Notes) 4.4 The Laplace Approximation
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            <time datetime="2019-04-14T09:08:04.000Z" itemprop="datePublished">Apr 14 2019</time>
        </span>
        
        
        <span class="column is-narrow">
            
            
            8 minutes read (About 1149 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <blockquote>
<p>A series of notes taken from <em>Pattern Recognition and Machine Learning</em>.</p>
</blockquote>
<p>For a Bayesian treatment of logistic regression, it is more complex than that of linear regression discuss before, since we cannot integrate analytically over <span class="math inline">\(\mathbf{w}\)</span> due to the posterior is no longer Gaussian. Instead, we should introduce some form of approximation.</p>
<a id="more"></a>
<h2 id="laplace-approximation">Laplace Approximation</h2>
<h3 id="univariate-approximation">Univariate Approximation</h3>
<p>Consider first the univariate case, the Laplace approximation aims to find a <em>local Gaussian approximation</em> <span class="math inline">\(q(z)\)</span> to a probability density <span class="math inline">\(p(z)\)</span> defined over a set of continuous variables.</p>
<p>Suppose <span class="math inline">\(p(z)â€‹\)</span> is defined from any function with finite integral <span class="math display">\[
p(z)=\frac{1}{Z} f(z), \text{ where } Z=\int f(z) \mathrm{d} z
\]</span> The first step of Laplace approximation is to find a mode of <span class="math inline">\(p(z)\)</span>, i.e. a point <span class="math inline">\(z_0\)</span> such that <span class="math inline">\(p&#39;(z_0)=0\)</span>. Next, since Gaussian has the property that its logarithm is quadratic, to do approximation we can consider a Taylor expansion of <span class="math inline">\(\ln f(z)\)</span> centered on <span class="math inline">\(z_0\)</span> <span class="math display">\[
\begin{align}
\ln f(z) &amp;\simeq \ln f\left(z_0\right) + \left. \frac{\mathrm{d}}{\mathrm{d}z}\ln f\left(z\right)\right|_{z=z_0}(z-z_{0}) +\frac{1}{2}\left. \frac{\mathrm{d}^2}{\mathrm{d}z^2}\ln f\left(z\right)\right|_{z=z_0}\left(z-z_{0}\right)^{2}
\\ &amp;= \ln f\left(z_0\right) +\frac{1}{2}\left. \frac{\mathrm{d}^2}{\mathrm{d}z^2}\ln f\left(z\right)\right|_{z=z_0}\left(z-z_{0}\right)^{2} &amp;&amp; \scriptstyle{(\text{Note that at mode we have zero-value first-order term.})}
\\ &amp; \equiv \ln f\left(z_0\right) -\frac{1}{2}A\left(z-z_{0}\right)^{2} &amp;&amp; \scriptstyle{(\text{Where we have defined } A=-\left. \frac{\mathrm{d}^2}{\mathrm{d}z^2}\ln f\left(z\right)\right|_{z=z_0})}
\end{align}
\]</span> Then take the exponential we have <span class="math display">\[
f(z) \simeq f\left(z_{0}\right) \exp \left\{-\frac{A}{2}\left(z-z_{0}\right)^{2}\right\}
\]</span> Then compute the normalization term of the approximated distribution <span class="math display">\[
Z_q=\int f\left(z_{0}\right) \exp \left\{-\frac{A}{2}\left(z-z_{0}\right)^{2}\right\} \mathrm{d} z = f(z_0) \left(\frac{2\pi}{A}\right)^{1/2}
\]</span> Now we can obtain the normalized approximated distribution <span class="math inline">\(q(z)\)</span> <span class="math display">\[
\begin{align}
q(z)&amp;=\frac{1}{Z_q} f\left(z_{0}\right) \exp \left\{-\frac{A}{2}\left(z-z_{0}\right)^{2}\right\} 
\\ &amp;= \left(\frac{A}{2 \pi}\right)^{1 / 2} \exp \left\{-\frac{A}{2}\left(z-z_{0}\right)^{2}\right\}
\end{align}
\]</span></p>
<blockquote>
<p>By this approach, only when the stationary point <span class="math inline">\(z_0\)</span> is a local maximum, i.e. when <span class="math inline">\(A&gt;0\)</span>, can the approximation be well defined.</p>
</blockquote>
<figure>
<img src="http://wiljohn-blog.oss-cn-shanghai.aliyuncs.com/19-04-04/Screenshot%20from%202019-04-14%2017-45-24.png" alt="Illustration of the Laplace approximation applied to the distribution p(z) \propto \exp \left(-z^{2} / 2\right) \text{sigmoid}(20 z+4)."><figcaption>Illustration of the Laplace approximation applied to the distribution <span class="math inline">\(p(z) \propto \exp \left(-z^{2} / 2\right) \text{sigmoid}(20 z+4)\)</span>.</figcaption>
</figure>
<h3 id="multivariate-approximation">Multivariate Approximation</h3>
<p>To approximate an <span class="math inline">\(M\)</span>-dimensional distribution <span class="math inline">\(p(\mathbf{z})=f(\mathbf{z}) / Z\)</span>, again we expand it around a stationary point <span class="math inline">\(\mathbf{z}_0\)</span> <span class="math display">\[
\ln f(\mathbf{z}) \simeq \ln f\left(\mathbf{z}_{0}\right)-\frac{1}{2}\left(\mathbf{z}-\mathbf{z}_{0}\right)^{\mathrm{T}} \mathbf{A}\left(\mathbf{z}-\mathbf{z}_{0}\right)
\]</span> where <span class="math inline">\(\mathbf{A}=-\nabla^2 \ln f (\mathbf{z}_0)\)</span>. Again take exponential of both sides we obtain <span class="math display">\[
f(\mathbf{z}) \simeq f\left(\mathbf{z}_{0}\right) \exp \left\{-\frac{1}{2}\left(\mathbf{z}-\mathbf{z}_{0}\right)^{\mathrm{T}} \mathbf{A}\left(\mathbf{z}-\mathbf{z}_{0}\right)\right\}
\]</span> After normalization we have <span class="math display">\[
\begin{align} Z_q &amp;=  \int f\left(\mathbf{z}_{0}\right) \exp \left\{-\frac{1}{2}\left(\mathbf{z}-\mathbf{z}_{0}\right)^{\mathrm{T}} \mathbf{A}\left(\mathbf{z}-\mathbf{z}_{0}\right)\right\} \mathrm{d} \mathbf{z} \\ &amp;=f\left(\mathbf{z}_{0}\right) \frac{(2 \pi)^{M / 2}}{|\mathbf{A}|^{1 / 2}} \tag{1} 
\end{align}
\]</span> Then the approximated distribution is given by <span class="math display">\[
q(\mathbf{z})=\frac{|\mathbf{A}|^{1 / 2}}{(2 \pi)^{M / 2}} \exp \left\{-\frac{1}{2}\left(\mathbf{z}-\mathbf{z}_{0}\right)^{\mathrm{T}} \mathbf{A}\left(\mathbf{z}-\mathbf{z}_{0}\right)\right\}=\mathcal{N}\left(\mathbf{z} | \mathbf{z}_{0}, \mathbf{A}^{-1}\right)
\]</span></p>
<h3 id="some-analysis">Some Analysis</h3>
<ul>
<li>Many distributions are multimodal, so there will be various Laplace approximation according to different mode.</li>
<li>Laplace approximation is most useful when number of observed points are large, since the posterior are more like Gaussian according to central limit theorem.</li>
<li>Laplace approximation is only applicable to real variables, so for variable like <span class="math inline">\(0 \leqslant \tau&lt;\infty\)</span> we can consider an approximation of transformation of the variable like <span class="math inline">\(\ln\tau\)</span>.</li>
<li><em>The most serious limitation</em> is that it is based purely on the aspects of the true distribution at a specific local value of the variable, and so <em>can fail to capture important global properties</em>.</li>
</ul>
<h2 id="model-comparison-and-bic">Model Comparison and BIC</h2>
<p>The equation <span class="math inline">\((1)\)</span>, which is the approximation to the normalization constant of <span class="math inline">\(f(\mathbf{z})\)</span> <span class="math display">\[
Z \simeq f\left(\mathbf{z}_{0}\right) \frac{(2 \pi)^{M / 2}}{|\mathbf{A}|^{1 / 2}}
\]</span> can be used to obtain an approximation to the model evidence. Recall that the model evidence is given by <span class="math display">\[
p(\mathcal{D} | \mathcal{M}_{i}) = \int p(\mathcal{D} | \mathbf{w}, \mathcal{M}_{i}) p(\mathbf{w} | \mathcal{M}_{i}) \mathrm{d} \mathbf{w}
\]</span> Let us omit the conditioning on <span class="math inline">\(\mathcal{M}_iâ€‹\)</span> to keep unclustered <span class="math display">\[
p(\mathcal{D})=\int p(\mathcal{D} | \mathbf{w}) p(\mathbf{w}) \mathrm{d} \mathbf{w}
\]</span> We can define <span class="math inline">\(f(\mathbf{w}) = p(\mathcal{D} | \mathbf{w}) p(\mathbf{w})â€‹\)</span>, and <span class="math inline">\(Z = p(\mathcal{D})â€‹\)</span>, then we can obtain the Laplace approximation to this posterior as <span class="math display">\[
\begin{align}
\ln p(\mathcal{D}) &amp;= \ln \int f(\mathbf{w}) \mathrm{d} \mathbf{w} 
\\ &amp;\simeq \ln \left( f\left(\mathbf{w}_{\mathrm{MAP}}\right)\frac{(2 \pi)^{M / 2}}{|\mathbf{A}|^{1 / 2}} \right)
\\ &amp;\simeq \ln \left( p(\mathcal{D} | \mathbf{w}_{\mathrm{MAP}}) p(\mathbf{w}_{\mathrm{MAP}})\frac{(2 \pi)^{M / 2}}{|\mathbf{A}|^{1 / 2}} \right)
\\&amp;=\ln p\left(\mathcal{D} | \mathbf{w}_{\mathrm{MAP}}\right)+\underbrace{\ln p\left(\mathbf{w}_{\mathrm{MAP}}\right)+\frac{M}{2} \ln (2 \pi)-\frac{1}{2} \ln |\mathbf{A}|}_{\text { Occam factor }} \tag{2}
\end{align}
\]</span> Here the <strong>Occam factor</strong> consists of terms that penalizes model complexity, and in this case <span class="math display">\[
\mathbf{A}=-\nabla_{\mathbf{w}}^2f(\mathbf{w}) =-\nabla^2_{\mathbf{w}} \ln p\left(\mathcal{D} | \mathbf{w}_{\mathrm{MAP}}\right) p\left(\mathbf{w}_{\mathrm{MAP}}\right)=-\nabla^2_{\mathbf{w}} \ln p\left(\mathbf{w}_{\mathrm{MAP}} | \mathcal{D}\right)
\]</span> <span class="math inline">\(|\mathbf{A}|\)</span> would be large if <span class="math inline">\(p\left(\mathbf{w} | \mathcal{D}\right)\)</span> is sharply peaked at <span class="math inline">\(\mathbf{w}_{\mathrm{MAP}}\)</span> as more data observed. If we assume the prior <span class="math inline">\(p(\mathbf{w})\)</span> is flat and broad, and <span class="math inline">\(\mathbf{A}\)</span> is full rank, then we can approximate <span class="math inline">\((2)\)</span> <em>very roughly</em> by <span class="math display">\[
\ln p(\mathcal{D}) \simeq\ln p\left(\mathcal{D} | \color{red}{\mathbf{w}_{\mathrm{MAP}}}\right) - \frac{1}{2}M\ln N
\]</span> where <span class="math inline">\(Nâ€‹\)</span> is the number of data points and <span class="math inline">\(Mâ€‹\)</span> the adjustable parameters in <span class="math inline">\(\mathbf{w}â€‹\)</span>. This result is called <strong>Bayesian Information Criterion (BIC)</strong>.</p>
<blockquote>
<p>Compare to AIC: <span class="math inline">\(\ln p(\mathcal{D}|{\color{red}\mathbf{w}_{\mathrm{ML}} }) -M\)</span>, BIC penalizes model complexity more heavily. Both of them are easy toe valuate, but can also give misleading results in practice.</p>
</blockquote>

    
    </div>
    
    <div class="columns is-variable is-1 is-multiline is-mobile">
    
        <span class="column is-narrow"><a class="tag is-light article-tag" href="/tags/PRML/">#PRML</a></span>
    
    </div>
    
    
    <div class="columns is-mobile is-multiline article-nav">
        <span class="column is-12-mobile is-half-desktop  article-nav-prev">
            
            <a href="/2019/04/14/PRML4-5/">(PRML Notes) 4.5 Bayesian Logistic Regression</a>
            
        </span>
        <span class="column is-12-mobile is-half-desktop  article-nav-next">
            
            <a href="/2019/04/11/PRML4-3/">(PRML Notes) 4.3 Probabilistic Discriminative Models</a>
            
        </span>
    </div>
    
</article>


<div class="sharebox">
    
<div class="sharethis-inline-share-buttons"></div>
<script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5c1be99859895a00110ffa34&amp;product=inline-share-buttons" async="async"></script>

</div>



<div class="comments">
    <h3 class="title is-4">Comments</h3>
    
<script>
    var disqus_config = function () {
        this.page.url = 'http://wiljohn.top/2019/04/14/PRML4-4/';
        this.page.identifier = 'prml4-4';
        
        this.language = 'en';
        
    };
    (function() {
        var d = document, s = d.createElement('script');  
        s.src = '//' + 'wiljohnhong-github-io' + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>

<div id="disqus_thread">
    
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
</div>

    </div>
</section>
    <footer class="footer">
    <div class="container">
        <div class="columns content">
            <div class="column is-narrow has-text-centered">
                &copy; 2019 wiljohn&nbsp;
                Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> & <a href="http://github.com/ppoffice/hexo-theme-minos">Minos</a>
            </div>
            <div class="column is-hidden-mobile"></div>

            
            <div class="column is-narrow">
                <div class="columns is-mobile is-multiline is-centered">
                
                    
                <a class="column is-narrow has-text-black" title="GitHub" href="https://github.com/wiljohnhong">
                    
                    GitHub
                    
                </a>
                
                </div>
            </div>
            
            
        </div>
    </div>
</footer>
    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script>

<!-- test if the browser is outdated -->
<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.js"></script>
<script>
    $(document).ready(function () {
        // plugin function, place inside DOM ready function
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        })
    });
</script>

<script>
    window.FontAwesomeConfig = {
        searchPseudoElements: true
    }
    moment.locale("en-AU");
</script>


    
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        "HTML-CSS": {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
</script>


    
    
<script src="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/js/lightgallery-all.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/js/jquery.justifiedGallery.min.js"></script>
<script>
    (function ($) {
        $(document).ready(function () {
            if (typeof($.fn.lightGallery) === 'function') {
                $('.article.gallery').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof($.fn.justifiedGallery) === 'function') {
                $('.justified-gallery').justifiedGallery();
            }
        });
    })(jQuery);
</script>

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
    <style>
        .hljs {
            position: relative;
        }

        .hljs .clipboard-btn {
            float: right;
            color: #9a9a9a;
            background: none;
            border: none;
            cursor: pointer;
        }

        .hljs .clipboard-btn:hover {
          color: #8a8a8a;
        }

        .hljs > .clipboard-btn {
            display: none;
            position: absolute;
            right: 4px;
            top: 4px;
        }

        .hljs:hover > .clipboard-btn {
            display: inline;
        }

        .hljs > figcaption > .clipboard-btn {
            margin-right: 4px;
        }
    </style>
    <script>
      $(document).ready(function () {
        $('figure.hljs').each(function(i, figure) {
          var codeId = 'code-' + i;
          var code = figure.querySelector('.code');
          var copyButton = $('<button>Copy <i class="far fa-clipboard"></i></button>');
          code.id = codeId;
          copyButton.addClass('clipboard-btn');
          copyButton.attr('data-clipboard-target-id', codeId);

          var figcaption = figure.querySelector('figcaption');

          if (figcaption) {
            figcaption.append(copyButton[0]);
          } else {
            figure.prepend(copyButton[0]);
          }
        })

        var clipboard = new ClipboardJS('.clipboard-btn', {
          target: function(trigger) {
            return document.getElementById(trigger.getAttribute('data-clipboard-target-id'));
          }
        });
        clipboard.on('success', function(e) {
          e.clearSelection();
        })
      })
    </script>

    


<script src="/js/script.js"></script>

    
    <div class="searchbox ins-search">
    <div class="searchbox-mask"></div>
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="Type something...">
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: 'Posts',
                PAGES: 'Pages',
                CATEGORIES: 'Categories',
                TAGS: 'Tags',
                UNTITLED: '(Untitled)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script src="/js/insight.js"></script>
    
</body>
</html>